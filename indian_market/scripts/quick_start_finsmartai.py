#!/usr/bin/env python3
"""
FinSmartAI Ecosystem Quick Start Script
This script helps you set up the foundational infrastructure for the FinSmartAI ecosystem.
"""

import os
import sys
import subprocess
import json
import shutil
from datetime import datetime

def print_banner():
    """Print the FinSmartAI banner"""
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                                               â•‘
    â•‘                    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—                 â•‘
    â•‘                    â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•                 â•‘
    â•‘                    â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—                 â•‘
    â•‘                    â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘                 â•‘
    â•‘                    â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘                 â•‘
    â•‘                     â•šâ•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•                 â•‘
    â•‘                                                                               â•‘
    â•‘                 Financial AI Ecosystem Quick Start Setup                      â•‘
    â•‘                                                                               â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)

def check_python_version():
    """Check if Python version is compatible"""
    print("ğŸ Checking Python version...")
    if sys.version_info < (3, 8):
        print("âŒ Python 3.8 or higher is required")
        sys.exit(1)
    print(f"âœ… Python {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro} is compatible")

def install_dependencies():
    """Install required dependencies for FinSmartAI ecosystem"""
    print("ğŸ“¦ Installing FinSmartAI dependencies...")
    
    dependencies = [
        # Core Frameworks
        'fastapi', 'uvicorn', 'pydantic', 'sqlalchemy', 'alembic',
        'psycopg2-binary', 'redis', 'celery', 'kafka-python',
        
        # AI/ML Frameworks
        'torch', 'torchvision', 'transformers', 'datasets',
        'tensorflow', 'scikit-learn', 'xgboost', 'lightgbm',
        'stable-baselines3', 'ray', 'optuna',
        
        # Data Processing
        'pandas', 'numpy', 'scipy', 'matplotlib', 'seaborn',
        'plotly', 'dash', 'streamlit', 'jupyter',
        
        # Web Frameworks
        'react', 'vue', 'django', 'flask', 'requests',
        'beautifulsoup4', 'selenium', 'websocket-client',
        
        # DevOps & Monitoring
        'docker', 'kubernetes', 'prometheus-client', 'grafana-api',
        'elasticsearch', 'logstash', 'kibana', 'newrelic',
        
        # Security
        'cryptography', 'pyjwt', 'bcrypt', 'oauthlib',
        
        # Testing
        'pytest', 'pytest-cov', 'pytest-asyncio', 'black',
        'flake8', 'mypy', 'pre-commit'
    ]
    
    for dep in dependencies:
        try:
            subprocess.run([sys.executable, '-m', 'pip', 'install', dep], 
                         check=True, capture_output=True)
            print(f"âœ… Installed {dep}")
        except subprocess.CalledProcessError as e:
            print(f"âŒ Failed to install {dep}: {e}")
    
    print("âœ… Dependencies installation completed!")

def create_directory_structure():
    """Create the FinSmartAI directory structure"""
    print("ğŸ“ Creating FinSmartAI directory structure...")
    
    base_dir = '/home/z/my-project/indian_market'
    
    directories = [
        # Core Application
        f'{base_dir}/finsmartai',
        f'{base_dir}/finsmartai/app',
        f'{base_dir}/finsmartai/app/api',
        f'{base_dir}/finsmartai/app/core',
        f'{base_dir}/finsmartai/app/models',
        f'{base_dir}/finsmartai/app/services',
        f'{base_dir}/finsmartai/app/database',
        f'{base_dir}/finsmartai/app/utils',
        
        # AI Models
        f'{base_dir}/finsmartai/models',
        f'{base_dir}/finsmartai/models/kronos_core',
        f'{base_dir}/finsmartai/models/sentimentai',
        f'{base_dir}/finsmartai/models/newsinsight',
        f'{base_dir}/finsmartai/models/optionsai',
        f'{base_dir}/finsmartai/models/riskai',
        f'{base_dir}/finsmartai/models/fundflowai',
        f'{base_dir}/finsmartai/models/mutualai',
        f'{base_dir}/finsmartai/models/commodai',
        f'{base_dir}/finsmartai/models/fxai',
        f'{base_dir}/finsmartai/models/taxai',
        f'{base_dir}/finsmartai/models/alphaai',
        f'{base_dir}/finsmartai/models/trendfusion',
        f'{base_dir}/finsmartai/models/global_markets',
        
        # Data
        f'{base_dir}/finsmartai/data',
        f'{base_dir}/finsmartai/data/raw',
        f'{base_dir}/finsmartai/data/processed',
        f'{base_dir}/finsmartai/data/external',
        f'{base_dir}/finsmartai/data/cache',
        
        # Web Application
        f'{base_dir}/finsmartai/web',
        f'{base_dir}/finsmartai/web/dashboard',
        f'{base_dir}/finsmartai/web/mobile',
        f'{base_dir}/finsmartai/web/admin',
        f'{base_dir}/finsmartai/web/static',
        f'{base_dir}/finsmartai/web/templates',
        
        # Infrastructure
        f'{base_dir}/finsmartai/infrastructure',
        f'{base_dir}/finsmartai/infrastructure/docker',
        f'{base_dir}/finsmartai/infrastructure/kubernetes',
        f'{base_dir}/finsmartai/infrastructure/exostack',
        f'{base_dir}/finsmartai/infrastructure/villagecloud',
        
        # Documentation
        f'{base_dir}/finsmartai/docs',
        f'{base_dir}/finsmartai/docs/api',
        f'{base_dir}/finsmartai/docs/models',
        f'{base_dir}/finsmartai/docs/deployment',
        f'{base_dir}/finsmartai/docs/tutorials',
        
        # Tests
        f'{base_dir}/finsmartai/tests',
        f'{base_dir}/finsmartai/tests/unit',
        f'{base_dir}/finsmartai/tests/integration',
        f'{base_dir}/finsmartai/tests/e2e',
        
        # Config
        f'{base_dir}/finsmartai/config',
        f'{base_dir}/finsmartai/scripts',
        f'{base_dir}/finsmartai/logs'
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"âœ… Created {directory}")
    
    print("âœ… Directory structure created!")

def create_config_files():
    """Create configuration files for the ecosystem"""
    print("âš™ï¸ Creating configuration files...")
    
    # Main configuration
    config_content = """
# FinSmartAI Configuration
import os
from typing import Dict, Any, List
from pydantic import BaseSettings

class DatabaseSettings(BaseSettings):
    """Database configuration"""
    url: str = os.getenv("DATABASE_URL", "postgresql://finsmartai:finsmartai@localhost:5432/finsmartai")
    pool_size: int = int(os.getenv("DB_POOL_SIZE", "20"))
    max_overflow: int = int(os.getenv("DB_MAX_OVERFLOW", "30"))
    echo: bool = os.getenv("DB_ECHO", "false").lower() == "true"

class RedisSettings(BaseSettings):
    """Redis configuration"""
    host: str = os.getenv("REDIS_HOST", "localhost")
    port: int = int(os.getenv("REDIS_PORT", "6379"))
    password: str = os.getenv("REDIS_PASSWORD", "")
    db: int = int(os.getenv("REDIS_DB", "0"))

class KafkaSettings(BaseSettings):
    """Kafka configuration"""
    bootstrap_servers: str = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "localhost:9092")
    consumer_group: str = os.getenv("KAFKA_CONSUMER_GROUP", "finsmartai")
    auto_offset_reset: str = os.getenv("KAFKA_AUTO_OFFSET_RESET", "earliest")

class SecuritySettings(BaseSettings):
    """Security configuration"""
    secret_key: str = os.getenv("SECRET_KEY", "your-secret-key-change-this-in-production")
    algorithm: str = "HS256"
    access_token_expire_minutes: int = int(os.getenv("ACCESS_TOKEN_EXPIRE_MINUTES", "30"))
    refresh_token_expire_days: int = int(os.getenv("REFRESH_TOKEN_EXPIRE_DAYS", "7"))

class ModelSettings(BaseSettings):
    """Model configuration"""
    model_dir: str = os.getenv("MODEL_DIR", "/app/models")
    cache_dir: str = os.getenv("CACHE_DIR", "/app/cache")
    max_sequence_length: int = int(os.getenv("MAX_SEQUENCE_LENGTH", "512"))
    batch_size: int = int(os.getenv("BATCH_SIZE", "32"))
    learning_rate: float = float(os.getenv("LEARNING_RATE", "0.001"))

class APISettings(BaseSettings):
    """API configuration"""
    host: str = os.getenv("API_HOST", "0.0.0.0")
    port: int = int(os.getenv("API_PORT", "8000"))
    workers: int = int(os.getenv("API_WORKERS", "4"))
    reload: bool = os.getenv("API_RELOAD", "false").lower() == "true"
    debug: bool = os.getenv("API_DEBUG", "false").lower() == "true"

class MonitoringSettings(BaseSettings):
    """Monitoring configuration"""
    prometheus_port: int = int(os.getenv("PROMETHEUS_PORT", "9090"))
    grafana_port: int = int(os.getenv("GRAFANA_PORT", "3000"))
    log_level: str = os.getenv("LOG_LEVEL", "INFO")
    metrics_enabled: bool = os.getenv("METRICS_ENABLED", "true").lower() == "true"

class Settings(BaseSettings):
    """Main settings class"""
    database: DatabaseSettings = DatabaseSettings()
    redis: RedisSettings = RedisSettings()
    kafka: KafkaSettings = KafkaSettings()
    security: SecuritySettings = SecuritySettings()
    model: ModelSettings = ModelSettings()
    api: APISettings = APISettings()
    monitoring: MonitoringSettings = MonitoringSettings()
    
    # Environment
    environment: str = os.getenv("ENVIRONMENT", "development")
    version: str = "1.0.0"
    debug: bool = environment == "development"
    
    # Feature flags
    enable_sentimentai: bool = os.getenv("ENABLE_SENTIMENTAI", "true").lower() == "true"
    enable_optionsai: bool = os.getenv("ENABLE_OPTIONSAI", "true").lower() == "true"
    enable_riskai: bool = os.getenv("ENABLE_RISKAI", "true").lower() == "true"
    enable_alphaai: bool = os.getenv("ENABLE_ALPHAI", "true").lower() == "true"
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

settings = Settings()
"""
    
    with open('/home/z/my-project/indian_market/finsmartai/config/settings.py', 'w') as f:
        f.write(config_content)
    
    # Environment file template
    env_template = """# FinSmartAI Environment Configuration
# Database
DATABASE_URL=postgresql://finsmartai:finsmartai@localhost:5432/finsmartai
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=30
DB_ECHO=false

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# Kafka
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_CONSUMER_GROUP=finsmartai
KAFKA_AUTO_OFFSET_RESET=earliest

# Security
SECRET_KEY=your-super-secret-key-change-this-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# Model Configuration
MODEL_DIR=/app/models
CACHE_DIR=/app/cache
MAX_SEQUENCE_LENGTH=512
BATCH_SIZE=32
LEARNING_RATE=0.001

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
API_RELOAD=false
API_DEBUG=false

# Monitoring
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
LOG_LEVEL=INFO
METRICS_ENABLED=true

# Environment
ENVIRONMENT=development
VERSION=1.0.0

# Feature Flags
ENABLE_SENTIMENTAI=true
ENABLE_OPTIONSAI=true
ENABLE_RISKAI=true
ENABLE_ALPHAAI=true

# External API Keys
TWITTER_API_KEY=your-twitter-api-key
TWITTER_API_SECRET=your-twitter-api-secret
TWITTER_BEARER_TOKEN=your-twitter-bearer-token
NEWS_API_KEY=your-news-api-key
NSE_API_KEY=your-nse-api-key
BSE_API_KEY=your-bse-api-key
MCX_API_KEY=your-mcx-api-key
"""
    
    with open('/home/z/my-project/indian_market/finsmartai/.env.template', 'w') as f:
        f.write(env_template)
    
    # Docker configuration
    dockerfile_content = """
FROM python:3.9-slim

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV DEBIAN_FRONTEND=noninteractive

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    g++ \\
    libpq-dev \\
    libffi-dev \\
    libssl-dev \\
    && rm -rf /var/lib/apt/lists/*

# Set work directory
WORKDIR /app

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy project
COPY . .

# Create non-root user
RUN useradd --create-home --shell /bin/bash app && chown -R app:app /app
USER app

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
"""
    
    with open('/home/z/my-project/indian_market/finsmartai/Dockerfile', 'w') as f:
        f.write(dockerfile_content)
    
    # Docker Compose
    docker_compose_content = """
version: '3.8'

services:
  # Main Application
  app:
    build: .
    ports:
      - "8000:8000"
    depends_on:
      - db
      - redis
      - kafka
    environment:
      - DATABASE_URL=postgresql://finsmartai:finsmartai@db:5432/finsmartai
      - REDIS_HOST=redis
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    volumes:
      - ./models:/app/models
      - ./logs:/app/logs
    restart: unless-stopped

  # Database
  db:
    image: postgres:13
    environment:
      POSTGRES_DB: finsmartai
      POSTGRES_USER: finsmartai
      POSTGRES_PASSWORD: finsmartai
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped

  # Redis
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

  # Kafka
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - kafka_data:/var/lib/kafka/data
    restart: unless-stopped

  # Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
    restart: unless-stopped

  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    restart: unless-stopped

  # Grafana
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    restart: unless-stopped

  # Nginx
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./infrastructure/nginx.conf:/etc/nginx/nginx.conf
      - ./web/static:/usr/share/nginx/html/static
    depends_on:
      - app
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  kafka_data:
  zookeeper_data:
  prometheus_data:
  grafana_data:
"""
    
    with open('/home/z/my-project/indian_market/finsmartai/docker-compose.yml', 'w') as f:
        f.write(docker_compose_content)
    
    print("âœ… Configuration files created!")

def create_core_application():
    """Create the core application structure"""
    print("ğŸŒ Creating core application structure...")
    
    # Main application file
    main_app_content = """
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from contextlib import asynccontextmanager
import uvicorn
import logging
from datetime import datetime

from config.settings import settings
from app.core.database import engine, Base
from app.core.security import get_current_user
from app.api.v1.api import api_router

# Configure logging
logging.basicConfig(level=getattr(logging, settings.monitoring.log_level))
logger = logging.getLogger(__name__)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan events"""
    logger.info("Starting FinSmartAI application...")
    
    # Create database tables
    Base.metadata.create_all(bind=engine)
    
    logger.info("FinSmartAI application started successfully")
    yield
    
    logger.info("Shutting down FinSmartAI application...")

# Create FastAPI application
app = FastAPI(
    title="FinSmartAI API",
    description="Financial AI Ecosystem API",
    version=settings.version,
    lifespan=lifespan
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include API routes
app.include_router(api_router, prefix="/api/v1")

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "message": "Welcome to FinSmartAI API",
        "version": settings.version,
        "environment": settings.environment,
        "timestamp": datetime.utcnow().isoformat()
    }

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": settings.version
    }

@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    """HTTP exception handler"""
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "timestamp": datetime.utcnow().isoformat()
        }
    )

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host=settings.api.host,
        port=settings.api.port,
        workers=settings.api.workers,
        reload=settings.api.reload,
        log_level=settings.monitoring.log_level.lower()
    )
"""
    
    with open('/home/z/my-project/indian_market/finsmartai/app/main.py', 'w') as f:
        f.write(main_app_content)
    
    # Database configuration
    db_content = """
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from config.settings import settings

# Create database engine
engine = create_engine(
    settings.database.url,
    pool_size=settings.database.pool_size,
    max_overflow=settings.database.max_overflow,
    echo=settings.database.echo
)

# Create session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Create base class for models
Base = declarative_base()

def get_db():
    """Get database session"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
"""
    
    with open('/home/z/my-project/indian_market/finsmartai/app/core/database.py', 'w') as f:
        f.write(db_content)
    
    # Security module
    security_content = """
from datetime import datetime, timedelta
from typing import Optional
from jose import JWTError, jwt
from passlib.context import CryptContext
from fastapi import HTTPException, status, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.models.user import User
from config.settings import settings

# Password context
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

# Security bearer
security = HTTPBearer()

def verify_password(plain_password: str, hashed_password: str) -> bool:
    """Verify password"""
    return pwd_context.verify(plain_password, hashed_password)

def get_password_hash(password: str) -> str:
    """Get password hash"""
    return pwd_context.hash(password)

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    """Create access token"""
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=settings.security.access_token_expire_minutes)
    
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, settings.security.secret_key, algorithm=settings.security.algorithm)
    return encoded_jwt

def create_refresh_token(data: dict):
    """Create refresh token"""
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(days=settings.security.refresh_token_expire_days)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, settings.security.secret_key, algorithm=settings.security.algorithm)
    return encoded_jwt

def verify_token(token: str) -> dict:
    """Verify token"""
    try:
        payload = jwt.decode(token, settings.security.secret_key, algorithms=[settings.security.algorithm])
        return payload
    except JWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )

async def get_current_user(
    credentials: HTTPAuthorizationCredentials = Depends(security),
    db: Session = Depends(get_db)
) -> User:
    """Get current user"""
    token = credentials.credentials
    payload = verify_token(token)
    
    user_id = payload.get("sub")
    if user_id is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    user = db.query(User).filter(User.id == user_id).first()
    if user is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="User not found",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    return user

async def get_current_active_user(current_user: User = Depends(get_current_user)) -> User:
    """Get current active user"""
    if not current_user.is_active:
        raise HTTPException(status_code=400, detail="Inactive user")
    return current_user
"""
    
    with open('/home/z/my-project/indian_market/finsmartai/app/core/security.py', 'w') as f:
        f.write(security_content)
    
    # API router
    api_content = """
from fastapi import APIRouter
from app.api.v1.endpoints import users, models, predictions, billing

api_router = APIRouter()

# Include endpoint routers
api_router.include_router(users.router, prefix="/users", tags=["users"])
api_router.include_router(models.router, prefix="/models", tags=["models"])
api_router.include_router(predictions.router, prefix="/predictions", tags=["predictions"])
api_router.include_router(billing.router, prefix="/billing", tags=["billing"])
"""
    
    with open('/home/z/my-project/indian_market/finsmartai/app/api/v1/api.py', 'w') as f:
        f.write(api_content)
    
    print("âœ… Core application structure created!")

def create_model_skeletons():
    """Create skeleton files for all AI models"""
    print("ğŸ¤– Creating AI model skeletons...")
    
    models = [
        'kronos_core', 'sentimentai', 'newsinsight', 'optionsai', 'riskai',
        'fundflowai', 'mutualai', 'commodai', 'fxai', 'taxai', 'alphaai',
        'trendfusion', 'global_markets'
    ]
    
    for model in models:
        model_dir = f'/home/z/my-project/indian_market/finsmartai/models/{model}'
        
        # Model base class
        model_content = f"""
from abc import ABC, abstractmethod
from typing import Dict, Any, List
import numpy as np
import pandas as pd
import torch
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class {model.title().replace('_', '')}Model(ABC):
    \"\"\"
    Abstract base class for {model} model
    \"\"\"
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.model = None
        self.tokenizer = None
        self.is_trained = False
        self.logger = logging.getLogger(f\"finsmartai.models.{model}\")
    
    @abstractmethod
    def load_model(self) -> None:
        \"\"\"Load the pre-trained model\"\"\"
        pass
    
    @abstractmethod
    def preprocess_data(self, data: Any) -> Any:
        \"\"\"Preprocess input data\"\"\"
        pass
    
    @abstractmethod
    def predict(self, data: Any) -> Dict[str, Any]:
        \"\"\"Make predictions\"\"\"
        pass
    
    @abstractmethod
    def postprocess_results(self, results: Any) -> Dict[str, Any]:
        \"\"\"Postprocess prediction results\"\"\"
        pass
    
    def train(self, training_data: Any) -> None:
        \"\"\"Train the model\"\"\"
        self.logger.info(f\"Training {model} model...\")
        # Implementation specific to each model
        pass
    
    def evaluate(self, test_data: Any) -> Dict[str, float]:
        \"\"\"Evaluate model performance\"\"\"
        self.logger.info(f\"Evaluating {model} model...\")
        # Implementation specific to each model
        return {{\"accuracy\": 0.0}}
    
    def save_model(self, path: str) -> None:
        \"\"\"Save model to disk\"\"\"
        self.logger.info(f\"Saving {model} model to {{path}}\")
        # Implementation specific to each model
        pass
    
    def load_model_from_path(self, path: str) -> None:
        \"\"\"Load model from disk\"\"\"
        self.logger.info(f\"Loading {model} model from {{path}}\")
        # Implementation specific to each model
        pass
    
    def get_model_info(self) -> Dict[str, Any]:
        \"\"\"Get model information\"\"\"
        return {{
            \"model_name\": model,
            \"version\": \"1.0.0\",
            \"is_trained\": self.is_trained,
            \"config\": self.config,
            \"last_updated\": datetime.utcnow().isoformat()
        }}
    
    def health_check(self) -> Dict[str, Any]:
        \"\"\"Perform health check\"\"\"
        return {{
            \"status\": \"healthy\",
            \"model_loaded\": self.model is not None,
            \"can_predict\": self.is_trained,
            \"timestamp\": datetime.utcnow().isoformat()
        }}

class {model.title().replace('_', '')}ModelImpl({model.title().replace('_', '')}Model):
    \"\"\"
    Implementation of {model} model
    \"\"\"
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.model_name = model
        self.load_model()
    
    def load_model(self) -> None:
        \"\"\"Load the pre-trained model\"\"\"
        try:
            # Model loading implementation
            self.logger.info(f\"Loading {{self.model_name}} model...\")
            # self.model = load_pretrained_model(self.config.get(\"model_path\"))
            self.is_trained = True
            self.logger.info(f\"{{self.model_name}} model loaded successfully\")
        except Exception as e:
            self.logger.error(f\"Failed to load {{self.model_name}} model: {{e}}\")
            raise
    
    def preprocess_data(self, data: Any) -> Any:
        \"\"\"Preprocess input data\"\"\"
        # Implementation specific to model
        return data
    
    def predict(self, data: Any) -> Dict[str, Any]:
        \"\"\"Make predictions\"\"\"
        if not self.is_trained:
            raise RuntimeError(f\"{{self.model_name}} model is not trained\")
        
        try:
            # Preprocess data
            processed_data = self.preprocess_data(data)
            
            # Make prediction
            # prediction = self.model(processed_data)
            
            # For now, return mock prediction
            prediction = {{
                \"prediction\": [0.5, 0.3, 0.2],
                \"confidence\": 0.85,
                \"timestamp\": datetime.utcnow().isoformat()
            }}
            
            # Postprocess results
            results = self.postprocess_results(prediction)
            
            return results
            
        except Exception as e:
            self.logger.error(f\"Prediction failed for {{self.model_name}}: {{e}}\")
            raise
    
    def postprocess_results(self, results: Any) -> Dict[str, Any]:
        \"\"\"Postprocess prediction results\"\"\"
        return {{
            \"model\": self.model_name,
            \"results\": results,
            \"timestamp\": datetime.utcnow().isoformat()
        }}
"""
        
        with open(f'{model_dir}/model.py', 'w') as f:
            f.write(model_content)
        
        # Model configuration
        config_content = f"""
# {model} Model Configuration
{model.upper()}_CONFIG = {{
    \"model_name\": \"{model}\",
    \"version\": \"1.0.0\",
    \"model_path\": \"/app/models/{model}/model.pth\",
    \"tokenizer_path\": \"/app/models/{model}/tokenizer.json\",
    \"max_sequence_length\": 512,
    \"batch_size\": 32,
    \"learning_rate\": 0.001,
    \"num_epochs\": 10,
    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",
    \"feature_columns\": [
        \"open\", \"high\", \"low\", \"close\", \"volume\"
    ],
    \"target_columns\": [
        \"target_price\"
    ],
    \"hyperparameters\": {{
        \"hidden_size\": 256,
        \"num_layers\": 6,
        \"num_attention_heads\": 8,
        \"dropout\": 0.1
    }}
}}

# Data sources for {model}
{model.upper()}_DATA_SOURCES = {{
    \"primary\": [
        \"nse\", \"bse\"
    ],
    \"secondary\": [
        \"yfinance\", \"quandl\"
    ],
    \"alternative\": [
        \"news\", \"social_media\"
    ]
}}

# API endpoints for {model}
{model.upper()}_API_ENDPOINTS = {{
    \"predict\": \"/api/v1/models/{model}/predict\",
    \"train\": \"/api/v1/models/{model}/train\",
    \"evaluate\": \"/api/v1/models/{model}/evaluate\",
    \"info\": \"/api/v1/models/{model}/info\"
}}
"""
        
        with open(f'{model_dir}/config.py', 'w') as f:
            f.write(config_content)
        
        # Model requirements
        requirements_content = f"""
# {model} Model Requirements
torch>=1.9.0
transformers>=4.20.0
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
"""
        
        with open(f'{model_dir}/requirements.txt', 'w') as f:
            f.write(requirements_content)
        
        print(f"âœ… Created {model} model skeleton")
    
    print("âœ… AI model skeletons created!")

def create_deployment_scripts():
    """Create deployment and orchestration scripts"""
    print("ğŸš€ Creating deployment scripts...")
    
    # Development startup script
    dev_script = """#!/bin/bash
# FinSmartAI Development Startup Script

echo "ğŸš€ Starting FinSmartAI Development Environment..."

# Check if virtual environment exists
if [ ! -d "venv" ]; then
    echo "ğŸ“¦ Creating virtual environment..."
    python3 -m venv venv
fi

# Activate virtual environment
echo "ğŸ”§ Activating virtual environment..."
source venv/bin/activate

# Install dependencies
echo "ğŸ“š Installing dependencies..."
pip install -r requirements.txt

# Set environment variables
echo "âš™ï¸ Setting environment variables..."
export FLASK_APP=app.main:app
export FLASK_ENV=development

# Start services
echo "ğŸŒ Starting services..."
docker-compose up -d db redis kafka

# Wait for services to be ready
echo "â³ Waiting for services to be ready..."
sleep 10

# Run database migrations
echo "ğŸ—„ï¸ Running database migrations..."
alembic upgrade head

# Start the application
echo "ğŸ¯ Starting FinSmartAI application..."
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
"""
    
    with open('/home/z/my-project/indian_market/finsmartai/scripts/start_dev.sh', 'w') as f:
        f.write(dev_script)
    
    # Production deployment script
    prod_script = """#!/bin/bash
# FinSmartAI Production Deployment Script

echo "ğŸš€ Deploying FinSmartAI to Production..."

# Build Docker images
echo "ğŸ³ Building Docker images..."
docker-compose -f docker-compose.yml build

# Stop existing services
echo "ğŸ›‘ Stopping existing services..."
docker-compose down

# Start services
echo "ğŸŒ Starting services..."
docker-compose up -d

# Run database migrations
echo "ğŸ—„ï¸ Running database migrations..."
docker-compose exec app alembic upgrade head

# Health check
echo "ğŸ¥ Performing health check..."
sleep 30
curl -f http://localhost:8000/health || exit 1

echo "âœ… FinSmartAI deployed successfully!"
"""
    
    with open('/home/z/my-project/indian_market/finsmartai/scripts/deploy_prod.sh', 'w') as f:
        f.write(prod_script)
    
    # Model training script
    training_script = """#!/bin/bash
# FinSmartAI Model Training Script

MODEL_NAME=${1:-kronos_core}
EPOCHS=${2:-10}
BATCH_SIZE=${3:-32}

echo "ğŸ¤– Training $MODEL_NAME model..."

# Activate virtual environment
source venv/bin/activate

# Set environment variables
export PYTHONPATH=/app
export MODEL_NAME=$MODEL_NAME
export EPOCHS=$EPOCHS
export BATCH_SIZE=$BATCH_SIZE

# Run training
python -m scripts.train_model --model $MODEL_NAME --epochs $EPOCHS --batch_size $BATCH_SIZE

echo "âœ… Model training completed!"
"""
    
    with open('/home/z/my-project/indian_market/finsmartai/scripts/train_model.sh', 'w') as f:
        f.write(training_script)
    
    # Make scripts executable
    os.chmod('/home/z/my-project/indian_market/finsmartai/scripts/start_dev.sh', 0o755)
    os.chmod('/home/z/my-project/indian_market/finsmartai/scripts/deploy_prod.sh', 0o755)
    os.chmod('/home/z/my-project/indian_market/finsmartai/scripts/train_model.sh', 0o755)
    
    print("âœ… Deployment scripts created!")

def create_documentation():
    """Create comprehensive documentation"""
    print("ğŸ“š Creating documentation...")
    
    # Main README
    readme_content = """# FinSmartAI Ecosystem

A comprehensive financial AI ecosystem that transforms Kronos India AI into a full-scale financial intelligence platform with 12 specialized AI models working in harmony.

## ğŸ¯ Overview

FinSmartAI is an integrated ecosystem of AI-powered financial models designed to provide comprehensive insights, predictions, and analytics for Indian and global financial markets. Built on the foundation of Kronos India AI, the ecosystem includes specialized models for:

- **Kronos-SentimentAI**: News and social media sentiment analysis
- **Kronos-NewsInsight**: AI-powered news summarization
- **Kronos-OptionsAI**: Options price prediction and strategy generation
- **Kronos-RiskAI**: Portfolio risk analysis and optimization
- **Kronos-FundFlowAI**: FII/DII flow prediction
- **Kronos-MutualAI**: Mutual fund ranking and performance prediction
- **Kronos-CommodAI**: Commodity price prediction
- **Kronos-FXAI**: Currency trend prediction
- **Kronos-TaxAI**: Tax optimization and financial planning
- **Kronos-AlphaAI**: Automated trading strategy generation
- **Kronos-TrendFusion**: Unified market forecasting
- **Kronos Global Markets**: International market coverage

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Docker and Docker Compose
- PostgreSQL 13+
- Redis 7+
- Apache Kafka

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/your-username/finsmartai.git
cd finsmartai
```

2. **Run the quick start script**
```bash
python scripts/quick_start_finsmartai.py
```

3. **Set up environment**
```bash
cp .env.template .env
# Edit .env with your configuration
```

4. **Start development environment**
```bash
./scripts/start_dev.sh
```

5. **Access the application**
- API: http://localhost:8000
- Documentation: http://localhost:8000/docs
- Grafana: http://localhost:3000

## ğŸ—ï¸ Architecture

### System Architecture

```
FinSmartAI Ecosystem
â”œâ”€â”€ Presentation Layer
â”‚   â”œâ”€â”€ Web Dashboard (React.js)
â”‚   â”œâ”€â”€ Mobile Apps (React Native)
â”‚   â”œâ”€â”€ API Gateway (FastAPI)
â”‚   â””â”€â”€ Admin Panel (Vue.js)
â”œâ”€â”€ Application Layer
â”‚   â”œâ”€â”€ Model Orchestration Service
â”‚   â”œâ”€â”€ User Management Service
â”‚   â”œâ”€â”€ Billing & Subscription Service
â”‚   â”œâ”€â”€ Data Processing Service
â”‚   â””â”€â”€ Analytics & Monitoring Service
â”œâ”€â”€ AI Model Layer
â”‚   â”œâ”€â”€ Kronos Core (Base Model)
â”‚   â”œâ”€â”€ 11 Specialized AI Models
â”‚   â””â”€â”€ Ensemble & Fusion Models
â”œâ”€â”€ Data Layer
â”‚   â”œâ”€â”€ Real-time Data Streams
â”‚   â”œâ”€â”€ Historical Data Lake
â”‚   â”œâ”€â”€ External API Integrations
â”‚   â””â”€â”€ Data Quality Management
â””â”€â”€ Infrastructure Layer
    â”œâ”€â”€ ExoStack Compute Nodes
    â”œâ”€â”€ VillageCloud Distributed Network
    â”œâ”€â”€ Storage Systems
    â””â”€â”€ Network & Security
```

### Microservices Architecture

The FinSmartAI ecosystem is built on a microservices architecture with the following core services:

1. **Model Service**: Handles AI model inference and training
2. **Data Service**: Manages data collection and processing
3. **User Service**: Handles user authentication and management
4. **Billing Service**: Manages subscriptions and payments
5. **Analytics Service**: Provides usage analytics and monitoring

## ğŸ¤– AI Models

### Available Models

| Model | Purpose | Data Inputs | Architecture |
|-------|---------|-------------|-------------|
| **Kronos-SentimentAI** | Sentiment analysis | News, social media | FinBERT + LSTM |
| **Kronos-NewsInsight** | News summarization | Financial news | Multilingual BART |
| **Kronos-OptionsAI** | Options prediction | Option chains | Transformer + GARCH |
| **Kronos-RiskAI** | Risk analysis | Portfolio data | GNN + Copula |
| **Kronos-FundFlowAI** | Flow prediction | FII/DII data | Temporal CNN |
| **Kronos-MutualAI** | Fund ranking | Fund data | XGBoost + Ensemble |
| **Kronos-CommodAI** | Commodity prediction | Commodity data | LSTM + Transformer |
| **Kronos-FXAI** | Currency prediction | Forex data | Seq2Seq + Attention |
| **Kronos-TaxAI** | Tax optimization | Financial data | Knowledge Graph |
| **Kronos-AlphaAI** | Strategy generation | Market data | Deep RL |
| **Kronos-TrendFusion** | Unified forecasting | All models | Ensemble Methods |
| **Kronos Global** | Global markets | Global data | Multi-modal |

### Model Integration

All models are integrated through a unified API gateway and share common infrastructure:

- **Data Pipeline**: Common data collection and processing
- **Model Registry**: Centralized model versioning and deployment
- **Monitoring**: Unified monitoring and alerting
- **Scalability**: Distributed computing through ExoStack

## ğŸŒ API Documentation

### Authentication

All API endpoints require authentication using JWT tokens:

```python
import requests

# Get access token
response = requests.post(
    "http://localhost:8000/api/v1/users/token",
    data={"username": "your_username", "password": "your_password"}
)
token = response.json()["access_token"]

# Use token in requests
headers = {"Authorization": f"Bearer {token}"}
```

### Model Prediction

Make predictions using any model:

```python
# Make prediction with SentimentAI
response = requests.post(
    "http://localhost:8000/api/v1/models/sentimentai/predict",
    headers=headers,
    json={
        "text": "Reliance Industries announces strong Q3 results",
        "symbol": "RELIANCE.NS"
    }
)
prediction = response.json()
```

### Available Endpoints

- `GET /api/v1/models` - List available models
- `GET /api/v1/models/{model_name}/info` - Get model information
- `POST /api/v1/models/{model_name}/predict` - Make prediction
- `POST /api/v1/models/{model_name}/train` - Train model
- `GET /api/v1/models/{model_name}/evaluate` - Evaluate model

## ğŸ’° Monetization

### Subscription Tiers

| Tier | Price | Features | Target Users |
|------|-------|----------|--------------|
| **Basic** | â‚¹999/month | Core models, basic features | Retail traders |
| **Professional** | â‚¹4,999/month | All models, API access | Professional traders |
| **Institutional** | â‚¹24,999/month | Advanced features, support | Institutions |
| **Enterprise** | â‚¹50,000+/month | Custom solutions, SLA | Large enterprises |

### API Pricing

- **Single Prediction**: â‚¹0.10 per call
- **Batch Prediction**: â‚¹0.05 per stock
- **Model Training**: â‚¹500/hour
- **Custom Development**: â‚¹5,000-10,000/hour

## ğŸ”„ Distributed Computing

### ExoStack Integration

FinSmartAI leverages ExoStack for distributed computing:

- **Model Training**: Parallel training across multiple nodes
- **Inference**: Distributed inference for scalability
- **Data Processing**: Distributed data pipelines
- **Resource Management**: Dynamic resource allocation

### VillageCloud Integration

VillageCloud provides specialized AI infrastructure:

- **GPU Clusters**: High-performance GPU computing
- **Model Serving**: Optimized model serving infrastructure
- **Data Storage**: High-speed data storage and retrieval
- **Networking**: Low-latency networking for real-time processing

## ğŸ“Š Monitoring & Analytics

### System Monitoring

- **Prometheus**: Metrics collection and alerting
- **Grafana**: Visualization and dashboards
- **ELK Stack**: Log aggregation and analysis
- **New Relic**: Application performance monitoring

### Model Monitoring

- **Prediction Accuracy**: Real-time accuracy tracking
- **Model Drift**: Detection of model performance degradation
- **Data Quality**: Data quality monitoring and alerts
- **Resource Usage**: Compute resource utilization tracking

## ğŸš€ Deployment

### Development

```bash
./scripts/start_dev.sh
```

### Production

```bash
./scripts/deploy_prod.sh
```

### Docker

```bash
docker-compose up -d
```

### Kubernetes

```bash
kubectl apply -f infrastructure/kubernetes/
```

## ğŸ§ª Testing

### Running Tests

```bash
# Run all tests
pytest

# Run specific test categories
pytest tests/unit/
pytest tests/integration/
pytest tests/e2e/
```

### Test Coverage

```bash
pytest --cov=app --cov-report=html
```

## ğŸ“š Documentation

### API Documentation

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Model Documentation

- **Model Guides**: `/docs/models/`
- **API References**: `/docs/api/`
- **Tutorials**: `/docs/tutorials/`

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“ Support

For support and questions:
- **Documentation**: `/docs/`
- **API Support**: api@finsmartai.com
- **Enterprise Support**: enterprise@finsmartai.com
- **Issues**: GitHub Issues

## ğŸ¯ Roadmap

### Phase 1 (Months 1-3)
- [x] Core infrastructure setup
- [ ] Kronos Core enhancement
- [ ] RiskAI implementation
- [ ] SentimentAI implementation

### Phase 2 (Months 4-6)
- [ ] OptionsAI development
- [ ] FundFlowAI development
- [ ] AlphaAI development
- [ ] Unified dashboard

### Phase 3 (Months 7-9)
- [ ] NewsInsight development
- [ ] MutualAI development
- [ ] CommodAI development

### Phase 4 (Months 10-12)
- [ ] FXAI development
- [ ] TaxAI development
- [ ] TrendFusion development

### Phase 5 (Months 13-18)
- [ ] Global Markets expansion
- [ ] Enterprise features
- [ ] Advanced analytics

---

FinSmartAI - Building the future of financial intelligence with AI.
"""
    
    with open('/home/z/my-project/indian_market/finsmartai/README.md', 'w') as f:
        f.write(readme_content)
    
    # API documentation
    api_docs_content = """# FinSmartAI API Documentation

## Authentication

All API endpoints require authentication using JWT tokens. Include the token in the Authorization header:

```
Authorization: Bearer <your-jwt-token>
```

### Getting Access Token

```bash
curl -X POST "http://localhost:8000/api/v1/users/token" \\
  -H "Content-Type: application/json" \\
  -d '{
    "username": "your_username",
    "password": "your_password"
  }'
```

## Models API

### List Available Models

```bash
curl -X GET "http://localhost:8000/api/v1/models" \\
  -H "Authorization: Bearer <token>"
```

### Get Model Information

```bash
curl -X GET "http://localhost:8000/api/v1/models/sentimentai/info" \\
  -H "Authorization: Bearer <token>"
```

### Make Prediction

```bash
curl -X POST "http://localhost:8000/api/v1/models/sentimentai/predict" \\
  -H "Authorization: Bearer <token>" \\
  -H "Content-Type: application/json" \\
  -d '{
    "text": "Reliance Industries announces strong Q3 results",
    "symbol": "RELIANCE.NS",
    "language": "en"
  }'
```

### Train Model

```bash
curl -X POST "http://localhost:8000/api/v1/models/sentimentai/train" \\
  -H "Authorization: Bearer <token>" \\
  -H "Content-Type: application/json" \\
  -d '{
    "training_data": "path/to/training/data",
    "epochs": 10,
    "batch_size": 32
  }'
```

## User Management API

### Register User

```bash
curl -X POST "http://localhost:8000/api/v1/users/register" \\
  -H "Content-Type: application/json" \\
  -d '{
    "email": "user@example.com",
    "password": "secure_password",
    "full_name": "John Doe",
    "phone": "+919876543210"
  }'
```

### Get User Profile

```bash
curl -X GET "http://localhost:8000/api/v1/users/profile" \\
  -H "Authorization: Bearer <token>"
```

### Update User Profile

```bash
curl -X PUT "http://localhost:8000/api/v1/users/profile" \\
  -H "Authorization: Bearer <token>" \\
  -H "Content-Type: application/json" \\
  -d '{
    "full_name": "John Doe",
    "phone": "+919876543210"
  }'
```

## Billing API

### Get Subscription Plans

```bash
curl -X GET "http://localhost:8000/api/v1/billing/plans" \\
  -H "Authorization: Bearer <token>"
```

### Subscribe to Plan

```bash
curl -X POST "http://localhost:8000/api/v1/billing/subscribe" \\
  -H "Authorization: Bearer <token>" \\
  -H "Content-Type: application/json" \\
  -d '{
    "plan_id": "professional",
    "payment_method_id": "pm_123456789"
  }'
```

### Get Usage Statistics

```bash
curl -X GET "http://localhost:8000/api/v1/billing/usage" \\
  -H "Authorization: Bearer <token>"
```

## Data API

### Get Real-time Data

```bash
curl -X GET "http://localhost:8000/api/v1/data/real-time/RELIANCE.NS" \\
  -H "Authorization: Bearer <token>"
```

### Get Historical Data

```bash
curl -X GET "http://localhost:8000/api/v1/data/historical/RELIANCE.NS?period=1y" \\
  -H "Authorization: Bearer <token>"
```

## Error Handling

All API endpoints return standardized error responses:

```json
{
  "error": "Error message",
  "error_code": "ERROR_CODE",
  "timestamp": "2024-01-01T00:00:00Z"
}
```

### Common Error Codes

- `400`: Bad Request
- `401`: Unauthorized
- `403`: Forbidden
- `404`: Not Found
- `422`: Validation Error
- `500`: Internal Server Error

## Rate Limiting

API calls are rate limited based on subscription tier:

- **Basic**: 100 calls/minute
- **Professional**: 1000 calls/minute
- **Institutional**: 10000 calls/minute
- **Enterprise**: Unlimited

Rate limit headers are included in responses:

```
X-RateLimit-Limit: 1000
X-RateLimit-Remaining: 999
X-RateLimit-Reset: 1640995200
```
"""
    
    with open('/home/z/my-project/indian_market/finsmartai/docs/api/README.md', 'w') as f:
        f.write(api_docs_content)
    
    print("âœ… Documentation created!")

def main():
    """Main function to run the quick start setup"""
    print_banner()
    
    try:
        check_python_version()
        create_directory_structure()
        install_dependencies()
        create_config_files()
        create_core_application()
        create_model_skeletons()
        create_deployment_scripts()
        create_documentation()
        
        print("\n" + "="*70)
        print("ğŸ‰ FinSmartAI Ecosystem Quick Start Completed Successfully!")
        print("="*70)
        print("\nğŸ“‹ Next Steps:")
        print("1. Edit finsmartai/.env with your configuration")
        print("2. Set up database: createdb finsmartai")
        print("3. Install external dependencies: pip install -r requirements.txt")
        print("4. Start development environment: ./scripts/start_dev.sh")
        print("5. Access the application: http://localhost:8000")
        print("\nğŸ“š Documentation:")
        print("- Main README: finsmartai/README.md")
        print("- API Documentation: finsmartai/docs/api/README.md")
        print("- Model Guides: finsmartai/docs/models/")
        print("\nğŸš€ Available Scripts:")
        print("- Development: ./scripts/start_dev.sh")
        print("- Production: ./scripts/deploy_prod.sh")
        print("- Model Training: ./scripts/train_model.sh <model_name>")
        print("\nğŸ¯ First Steps:")
        print("1. Implement Kronos Core enhancements")
        print("2. Build RiskAI (highest priority)")
        print("3. Implement SentimentAI")
        print("4. Create unified dashboard")
        print("5. Set up billing and subscriptions")
        
        print(f"\nğŸ“ Project created at: /home/z/my-project/indian_market/finsmartai")
        print("ğŸŒŸ Welcome to the FinSmartAI Ecosystem!")
        
    except Exception as e:
        print(f"âŒ Error during setup: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()