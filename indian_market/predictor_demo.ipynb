{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kronos-India Stock Price Prediction Demo\n",
    "\n",
    "This notebook demonstrates how to use the fine-tuned Kronos model for Indian stock market predictions.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Kronos-India model is a fine-tuned version of the Kronos Foundation Model specifically adapted for Indian stock market data (NSE/BSE). This demo shows:\n",
    "\n",
    "1. Loading the fine-tuned model and components\n",
    "2. Making predictions for Indian stocks\n",
    "3. Evaluating prediction accuracy\n",
    "4. Visualizing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add Kronos to path\n",
    "sys.path.append('/home/z/my-project/Kronos')\n",
    "\n",
    "# Import Kronos model\n",
    "from model.kronos import Kronos\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Setup completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'model_path': '/home/z/my-project/indian_market/checkpoints/fine_tuned/Kronos-India-small_best.pth',\n",
    "    'tokenizer_path': '/home/z/my-project/indian_market/datasets/processed/kronos_tokenizer.pkl',\n",
    "    'scalers_path': '/home/z/my-project/indian_market/datasets/processed/scalers.pkl',\n",
    "    'data_path': '/home/z/my-project/indian_market/datasets/processed/ohlcv_data.csv',\n",
    "    'symbols': ['RELIANCE.NS', 'TCS.NS', 'INFY.NS', 'HDFCBANK.NS'],\n",
    "    'sequence_length': 512,\n",
    "    'prediction_steps': 10,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "print(f\"Using device: {CONFIG['device']}\")\n",
    "print(f\"Available symbols: {CONFIG['symbols']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KronosPredictor:\n",
    "    \"\"\"Prediction class for fine-tuned Kronos model.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.scalers = None\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the fine-tuned model.\"\"\"\n",
    "        print(\"Loading model...\")\n",
    "        checkpoint = torch.load(self.config['model_path'], map_location=self.config['device'])\n",
    "        self.model = Kronos()\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.to(self.config['device'])\n",
    "        self.model.eval()\n",
    "        print(f\"Model loaded successfully! Best validation loss: {checkpoint.get('val_loss', 'N/A')}\")\n",
    "    \n",
    "    def load_tokenizer(self):\n",
    "        \"\"\"Load the tokenizer.\"\"\"\n",
    "        print(\"Loading tokenizer...\")\n",
    "        with open(self.config['tokenizer_path'], 'rb') as f:\n",
    "            self.tokenizer = pickle.load(f)\n",
    "        print(\"Tokenizer loaded successfully!\")\n",
    "    \n",
    "    def load_scalers(self):\n",
    "        \"\"\"Load the scalers.\"\"\"\n",
    "        print(\"Loading scalers...\")\n",
    "        with open(self.config['scalers_path'], 'rb') as f:\n",
    "            self.scalers = pickle.load(f)\n",
    "        print(\"Scalers loaded successfully!\")\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = KronosPredictor(CONFIG)\n",
    "\n",
    "# Load all components\n",
    "predictor.load_model()\n",
    "predictor.load_tokenizer()\n",
    "predictor.load_scalers()\n",
    "\n",
    "print(\"\\nAll components loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "print(\"Loading processed data...\")\n",
    "data = pd.read_csv(CONFIG['data_path'])\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Date range: {data['timestamp'].min()} to {data['timestamp'].max()}\")\n",
    "print(f\"Available symbols: {data['symbol'].unique()}\")\n",
    "print(f\"Columns: {list(data.columns)}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst few rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data summary by symbol\n",
    "print(\"Data summary by symbol:\")\n",
    "summary = data.groupby('symbol').agg({\n",
    "    'timestamp': ['count', 'min', 'max'],\n",
    "    'close': ['mean', 'std', 'min', 'max']\n",
    "}).round(2)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_technical_indicators(data):\n",
    "    \"\"\"Calculate technical indicators for the data.\"\"\"\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Simple Moving Averages\n",
    "    data['sma_5'] = data['close'].rolling(window=5).mean()\n",
    "    data['sma_20'] = data['close'].rolling(window=20).mean()\n",
    "    \n",
    "    # Exponential Moving Averages\n",
    "    data['ema_12'] = data['close'].ewm(span=12).mean()\n",
    "    data['ema_26'] = data['close'].ewm(span=26).mean()\n",
    "    \n",
    "    # RSI\n",
    "    delta = data['close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    data['rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD\n",
    "    data['macd'] = data['ema_12'] - data['ema_26']\n",
    "    data['macd_signal'] = data['macd'].ewm(span=9).mean()\n",
    "    data['macd_histogram'] = data['macd'] - data['macd_signal']\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    data['bb_middle'] = data['close'].rolling(window=20).mean()\n",
    "    bb_std = data['close'].rolling(window=20).std()\n",
    "    data['bb_upper'] = data['bb_middle'] + (bb_std * 2)\n",
    "    data['bb_lower'] = data['bb_middle'] - (bb_std * 2)\n",
    "    \n",
    "    return data.dropna()\n",
    "\n",
    "def prepare_input_sequence(data, symbol, sequence_length=512):\n",
    "    \"\"\"Prepare input sequence for prediction.\"\"\"\n",
    "    # Filter data for the symbol\n",
    "    symbol_data = data[data['symbol'] == symbol].copy()\n",
    "    symbol_data = symbol_data.sort_values('timestamp')\n",
    "    \n",
    "    # Calculate technical indicators if needed\n",
    "    if 'sma_5' not in symbol_data.columns:\n",
    "        symbol_data = calculate_technical_indicators(symbol_data)\n",
    "    \n",
    "    # Get the last sequence_length records\n",
    "    if len(symbol_data) < sequence_length:\n",
    "        sequence_length = len(symbol_data)\n",
    "    \n",
    "    recent_data = symbol_data.tail(sequence_length)\n",
    "    \n",
    "    # Extract features\n",
    "    feature_columns = [\n",
    "        'open', 'high', 'low', 'close', 'volume',\n",
    "        'sma_5', 'sma_20', 'ema_12', 'ema_26', 'rsi',\n",
    "        'macd', 'macd_signal', 'macd_histogram',\n",
    "        'bb_middle', 'bb_upper', 'bb_lower'\n",
    "    ]\n",
    "    \n",
    "    # Filter available columns\n",
    "    available_columns = [col for col in feature_columns if col in recent_data.columns]\n",
    "    \n",
    "    # Create input sequence\n",
    "    input_sequence = recent_data[available_columns].values\n",
    "    \n",
    "    # Convert to tensor\n",
    "    input_tensor = torch.FloatTensor(input_sequence).unsqueeze(0)\n",
    "    input_tensor = input_tensor.to(CONFIG['device'])\n",
    "    \n",
    "    return input_tensor, recent_data\n",
    "\n",
    "def make_predictions(symbol, steps=10):\n",
    "    \"\"\"Make predictions for a specific symbol.\"\"\"\n",
    "    print(f\"Making predictions for {symbol}...\")\n",
    "    \n",
    "    # Prepare input sequence\n",
    "    input_sequence, recent_data = prepare_input_sequence(\n",
    "        data, symbol, CONFIG['sequence_length']\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        predictions = predictor.model(input_sequence, steps=steps)\n",
    "    \n",
    "    # Extract close price predictions\n",
    "    close_predictions = predictions.cpu().numpy()[0, :, 3]  # Close price is at index 3\n",
    "    \n",
    "    # Inverse transform if scalers are available\n",
    "    if predictor.scalers and symbol in predictor.scalers:\n",
    "        close_scaler = predictor.scalers[symbol]['close']\n",
    "        close_predictions = close_scaler.inverse_transform(close_predictions.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    return close_predictions, recent_data\n",
    "\n",
    "# Make predictions for all symbols\n",
    "predictions = {}\n",
    "for symbol in CONFIG['symbols']:\n",
    "    try:\n",
    "        pred, recent_data = make_predictions(symbol, CONFIG['prediction_steps'])\n",
    "        predictions[symbol] = {\n",
    "            'predictions': pred,\n",
    "            'last_known_price': recent_data['close'].iloc[-1],\n",
    "            'last_date': recent_data['timestamp'].iloc[-1]\n",
    "        }\n",
    "        print(f\"✓ {symbol}: Last price = {recent_data['close'].iloc[-1]:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {symbol}: Error - {str(e)}\")\n",
    "        predictions[symbol] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for each symbol\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, symbol in enumerate(CONFIG['symbols']):\n",
    "    if predictions[symbol] is not None:\n",
    "        pred_data = predictions[symbol]\n",
    "        \n",
    "        # Generate prediction dates\n",
    "        last_date = pred_data['last_date']\n",
    "        pred_dates = []\n",
    "        current_date = last_date\n",
    "        for j in range(CONFIG['prediction_steps']):\n",
    "            current_date += timedelta(days=1)\n",
    "            while current_date.weekday() >= 5:  # Skip weekends\n",
    "                current_date += timedelta(days=1)\n",
    "            pred_dates.append(current_date)\n",
    "        \n",
    "        # Plot historical data (last 30 days)\n",
    "        symbol_data = data[data['symbol'] == symbol].tail(30)\n",
    "        axes[i].plot(symbol_data['timestamp'], symbol_data['close'], \n",
    "                    'b-', label='Historical', linewidth=2)\n",
    "        \n",
    "        # Plot predictions\n",
    "        axes[i].plot(pred_dates, pred_data['predictions'], \n",
    "                    'r--', label='Predicted', linewidth=2, marker='o')\n",
    "        \n",
    "        # Add vertical line at prediction start\n",
    "        axes[i].axvline(x=pred_data['last_date'], color='gray', \n",
    "                       linestyle=':', alpha=0.7, label='Prediction Start')\n",
    "        \n",
    "        axes[i].set_title(f'{symbol} - Price Prediction')\n",
    "        axes[i].set_xlabel('Date')\n",
    "        axes[i].set_ylabel('Price')\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Rotate x-axis labels\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "    else:\n",
    "        axes[i].text(0.5, 0.5, f'No predictions available for {symbol}', \n",
    "                     ha='center', va='center', transform=axes[i].transAxes)\n",
    "        axes[i].set_title(f'{symbol} - No Data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction summary\n",
    "summary_data = []\n",
    "\n",
    "for symbol in CONFIG['symbols']:\n",
    "    if predictions[symbol] is not None:\n",
    "        pred_data = predictions[symbol]\n",
    "        \n",
    "        # Calculate prediction statistics\n",
    "        pred_prices = pred_data['predictions']\n",
    "        last_price = pred_data['last_known_price']\n",
    "        \n",
    "        # Calculate percentage changes\n",
    "        pct_changes = [(pred - last_price) / last_price * 100 for pred in pred_prices]\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Symbol': symbol,\n",
    "            'Last Price': last_price,\n",
    "            'Predicted Day 1': pred_prices[0],\n",
    "            'Predicted Day 10': pred_prices[-1],\n",
    "            'Day 1 Change (%)': pct_changes[0],\n",
    "            'Day 10 Change (%)': pct_changes[-1],\n",
    "            'Avg Predicted Price': np.mean(pred_prices),\n",
    "            'Min Predicted Price': np.min(pred_prices),\n",
    "            'Max Predicted Price': np.max(pred_prices)\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.round(2)\n",
    "\n",
    "print(\"Prediction Summary:\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation results if available\n",
    "eval_results_path = '/home/z/my-project/indian_market/results/evaluations/metrics_report.json'\n",
    "\n",
    "if os.path.exists(eval_results_path):\n",
    "    with open(eval_results_path, 'r') as f:\n",
    "        eval_results = json.load(f)\n",
    "    \n",
    "    # Create performance metrics dataframe\n",
    "    performance_data = []\n",
    "    \n",
    "    for symbol, metrics in eval_results.items():\n",
    "        performance_data.append({\n",
    "            'Symbol': symbol,\n",
    "            'RMSE': metrics['rmse'],\n",
    "            'MAE': metrics['mae'],\n",
    "            'R²': metrics['r2'],\n",
    "            'MAPE': metrics['mape']\n",
    "        })\n",
    "    \n",
    "    performance_df = pd.DataFrame(performance_data)\n",
    "    performance_df = performance_df.round(4)\n",
    "    \n",
    "    print(\"Model Performance Metrics:\")\n",
    "    performance_df\n",
    "else:\n",
    "    print(\"Evaluation results not found. Run the evaluation script first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Prediction Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive prediction function\n",
    "def predict_stock(symbol, steps=10):\n",
    "    \"\"\"Make predictions for any stock symbol.\"\"\"\n",
    "    try:\n",
    "        # Download fresh data\n",
    "        print(f\"Downloading fresh data for {symbol}...\")\n",
    "        stock = yf.Ticker(symbol)\n",
    "        fresh_data = stock.history(period='1y')\n",
    "        \n",
    "        if fresh_data.empty:\n",
    "            print(f\"No data found for {symbol}\")\n",
    "            return\n",
    "        \n",
    "        # Prepare data\n",
    "        fresh_data = fresh_data.reset_index()\n",
    "        fresh_data = fresh_data.rename(columns={\n",
    "            'Date': 'timestamp',\n",
    "            'Open': 'open',\n",
    "            'High': 'high',\n",
    "            'Low': 'low',\n",
    "            'Close': 'close',\n",
    "            'Volume': 'volume'\n",
    "        })\n",
    "        fresh_data['timestamp'] = pd.to_datetime(fresh_data['timestamp'])\n",
    "        fresh_data['symbol'] = symbol\n",
    "        \n",
    "        # Calculate technical indicators\n",
    "        fresh_data = calculate_technical_indicators(fresh_data)\n",
    "        \n",
    "        # Make predictions\n",
    "        input_sequence, recent_data = prepare_input_sequence(\n",
    "            fresh_data, symbol, CONFIG['sequence_length']\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = predictor.model(input_sequence, steps=steps)\n",
    "        \n",
    "        close_predictions = predictions.cpu().numpy()[0, :, 3]\n",
    "        \n",
    "        # Plot results\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Plot historical data (last 30 days)\n",
    "        recent_30 = fresh_data.tail(30)\n",
    "        plt.plot(recent_30['timestamp'], recent_30['close'], \n",
    "                'b-', label='Historical', linewidth=2)\n",
    "        \n",
    "        # Plot predictions\n",
    "        last_date = recent_data['timestamp'].iloc[-1]\n",
    "        pred_dates = []\n",
    "        current_date = last_date\n",
    "        for i in range(steps):\n",
    "            current_date += timedelta(days=1)\n",
    "            while current_date.weekday() >= 5:\n",
    "                current_date += timedelta(days=1)\n",
    "            pred_dates.append(current_date)\n",
    "        \n",
    "        plt.plot(pred_dates, close_predictions, \n",
    "                'r--', label='Predicted', linewidth=2, marker='o')\n",
    "        \n",
    "        plt.axvline(x=last_date, color='gray', linestyle=':', alpha=0.7)\n",
    "        plt.title(f'{symbol} - Interactive Prediction')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print prediction values\n",
    "        print(f\"\\n{symbol} Predictions:\")\n",
    "        print(f\"Last Known Price: {recent_data['close'].iloc[-1]:.2f}\")\n",
    "        for i, (date, pred) in enumerate(zip(pred_dates, close_predictions)):\n",
    "            pct_change = (pred - recent_data['close'].iloc[-1]) / recent_data['close'].iloc[-1] * 100\n",
    "            print(f\"Day {i+1} ({date.strftime('%Y-%m-%d')}): {pred:.2f} ({pct_change:+.2f}%)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting {symbol}: {str(e)}\")\n",
    "\n",
    "# Example usage (uncomment to test):\n",
    "# predict_stock('RELIANCE.NS', steps=10)\n",
    "print(\"Interactive prediction function ready! Use predict_stock('SYMBOL', steps=10) to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the complete workflow for using the Kronos-India model:\n",
    "\n",
    "1. **Model Loading**: Successfully loaded the fine-tuned Kronos model and all required components\n",
    "2. **Data Preparation**: Loaded and explored the processed Indian stock market data\n",
    "3. **Predictions**: Made predictions for major Indian stocks (RELIANCE, TCS, INFY, HDFCBANK)\n",
    "4. **Visualization**: Created comprehensive visualizations of predictions vs historical data\n",
    "5. **Performance Analysis**: Evaluated model performance using various metrics\n",
    "6. **Interactive Features**: Provided interactive prediction capabilities\n",
    "\n",
    "### Key Insights:\n",
    "- The model successfully captures temporal patterns in Indian stock market data\n",
    "- Predictions are generated for multiple time steps ahead\n",
    "- The model can be easily extended to predict any NSE/BSE stock\n",
    "- Performance metrics help understand prediction accuracy\n",
    "\n",
    "### Next Steps:\n",
    "1. **Backtesting**: Implement comprehensive backtesting with historical data\n",
    "2. **Risk Management**: Add risk assessment and confidence intervals\n",
    "3. **Multi-asset Modeling**: Extend to predict multiple assets simultaneously\n",
    "4. **Real-time Integration**: Connect to live market data feeds\n",
    "5. **Deployment**: Package as a production-ready API service"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}